{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gans.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Nto-M3lZODHK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HELPERS\n"
      ]
    },
    {
      "metadata": {
        "id": "Tay3l2P3jPAw",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pytorch\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def to_gpu(x):\n",
        "  if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mwC8rxDpOYtt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training GANS\n"
      ]
    },
    {
      "metadata": {
        "id": "Yz-9haiC2gXo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Architecture\n",
        "\n",
        "![](https://sthalles.github.io/assets/dcgan/GANs.png)\n",
        "\n",
        "## GAN seen as a *minmax* game\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1KVkTMjTT7jr8gfIv-1c4LRosrCZRpJd9)\n",
        "\n",
        "## Training intuition\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=15G9ZuSZqLG-E8LufyT-UnN9V0lme3nJZ)\n",
        "\n",
        "## Training procedure\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1_JMKgK48QbhU9W9F9DG6dPQpYZPcYGSE)\n"
      ]
    },
    {
      "metadata": {
        "id": "_UIg3wz5dAML",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gan_magic(generator, discriminator, data_loader, noise, plot, epochs=100,\n",
        "              disc_steps=1, test_samples=10, draw_every_n=1, d_lr=0.001, g_lr=0.001):\n",
        "  # Total number of epochs to train\n",
        "  num_epochs = epochs\n",
        "\n",
        "  test_noise = noise(test_samples)\n",
        "  \n",
        "  d_optimizer = optim.Adam(discriminator.parameters(), lr=d_lr)\n",
        "  g_optimizer = optim.Adam(generator.parameters(), lr=g_lr)\n",
        "  \n",
        "  loss = nn.BCELoss()\n",
        "  \n",
        "  def train_discriminator(optimizer, real_data, fake_data):\n",
        "    N = real_data.size(0)\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Train on Real Data\n",
        "    prediction_real = discriminator(real_data)\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    error_real = loss(prediction_real, ones_target(N) )\n",
        "    error_real.backward()\n",
        "\n",
        "    # 1.2 Train on Fake Data\n",
        "    prediction_fake = discriminator(fake_data)\n",
        "    # Calculate error and backpropagate\n",
        "    error_fake = loss(prediction_fake, zeros_target(N))\n",
        "    error_fake.backward()\n",
        "    \n",
        "    # 1.3 Update weights with gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Return error and predictions for real and fake inputs\n",
        "    return error_real + error_fake, prediction_real, prediction_fake\n",
        "  \n",
        "  def train_generator(optimizer, fake_data):\n",
        "    N = fake_data.size(0)\n",
        "\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data)\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    error = loss(prediction, ones_target(N))\n",
        "    error.backward()\n",
        "\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # Return error\n",
        "    return error\n",
        "  \n",
        "\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "          N = real_batch.size(0)\n",
        "          \n",
        "          real_data = to_gpu(Variable(real_batch))\n",
        "\n",
        "          # 1. Train Discriminator\n",
        "          # 1.1 Generate fake data and detach \n",
        "          # (so gradients are not calculated for generator)\n",
        "          fake_data = generator(noise(N)).detach()\n",
        "          # 1.2 Train D\n",
        "          d_error, d_pred_real, d_pred_fake = \\\n",
        "              train_discriminator(d_optimizer, real_data, fake_data)\n",
        "      \n",
        "          # 2. Train Generator every \"k = disc_steps\" steps\n",
        "          if n_batch % disc_steps == 0:        \n",
        "            # 2.1 Generate fake data again\n",
        "            fake_data = generator(noise(N))\n",
        "            # 2.2 Train G\n",
        "            g_error = train_generator(g_optimizer, fake_data)\n",
        "\n",
        "      # Display samples every few batches\n",
        "      if epoch % draw_every_n == 0: \n",
        "          test_images = generator(test_noise).cpu()\n",
        "          test_images = test_images.data\n",
        "          plot(test_images)\n",
        "          \n",
        "      # Display status Logs\n",
        "      display_status(\n",
        "          epoch, num_epochs,\n",
        "          d_error, g_error, d_pred_real, d_pred_fake\n",
        "      )\n",
        "        \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6h8yoBSyghtR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_status(epoch, num_epochs, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "\n",
        "    # var_class = torch.autograd.variable.Variable\n",
        "    if isinstance(d_error, torch.autograd.Variable):\n",
        "        d_error = d_error.data.cpu().numpy()\n",
        "    if isinstance(g_error, torch.autograd.Variable):\n",
        "        g_error = g_error.data.cpu().numpy()\n",
        "    if isinstance(d_pred_real, torch.autograd.Variable):\n",
        "        d_pred_real = d_pred_real.data\n",
        "    if isinstance(d_pred_fake, torch.autograd.Variable):\n",
        "        d_pred_fake = d_pred_fake.data\n",
        "\n",
        "\n",
        "    print('Epoch: [{}/{}]'.format(epoch,num_epochs))\n",
        "    print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "    print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mq4oX0dnjPCM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ones_target(size):\n",
        "    '''\n",
        "    Tensor containing ones, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    return to_gpu(data)\n",
        "def zeros_target(size):\n",
        "    '''\n",
        "    Tensor containing zeros, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    return to_gpu(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qPRCr9BXOKx8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vanilla GAN"
      ]
    },
    {
      "metadata": {
        "id": "_fuwfsnqr3LJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LATENT_SIZE = 10\n",
        "BATCH_SIZE = 32\n",
        "TEST_SAMPLES = 16\n",
        "\n",
        "def circle_noise(size):\n",
        "    '''\n",
        "    Generates a 1-d vector of gaussian sampled random values\n",
        "    '''\n",
        "    n = Variable(torch.rand(size, LATENT_SIZE))\n",
        "    return to_gpu(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tdy3147_mg_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# generate 2d classification dataset\n",
        "X, _ = make_circles(n_samples=400, noise=0.05, factor=0.99)\n",
        "\n",
        "def plot_circle(data):\n",
        "  xax = data[:,0]\n",
        "  yax = data[:,1]\n",
        "\n",
        "  plt.scatter(xax, yax, c='red')\n",
        "  plt.show()\n",
        "\n",
        "class CircleGenerator:\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    \n",
        "    \n",
        "  def gen_batches(self):\n",
        "    for _ in range(len(self.data) // BATCH_SIZE):\n",
        "      dcopy = self.data.copy()\n",
        "      np.random.shuffle(dcopy)\n",
        "      yield torch.from_numpy(dcopy[:BATCH_SIZE].astype(np.float32)), None # second one just for compatibility\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self.gen_batches()\n",
        "\n",
        "  \n",
        "circle_data_loader = CircleGenerator(X)\n",
        "\n",
        "plot_circle(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5hkdIMn3p7OO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer discriminative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        n_features = 2\n",
        "        n_out = 1\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 50),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(50, 20),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(20, n_out),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "discriminator = to_gpu(DiscriminatorNet())\n",
        "\n",
        "\n",
        "class GeneratorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer generative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 10\n",
        "        n_out = 2\n",
        "        \n",
        "        self.hidden0 = nn.Sequential(\n",
        "            nn.Linear(n_features, 20),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(            \n",
        "            nn.Linear(20, 50),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(50, n_out),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "generator = to_gpu(GeneratorNet())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kE9sWonNr-47",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gan_magic(generator, discriminator, circle_data_loader, circle_noise,\n",
        "          plot_circle, epochs=1000, disc_steps=10, test_samples=200, draw_every_n=10, d_lr=0.01, g_lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZnfHDMzKNxmv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "53UJlmsyu4eZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LATENT_SIZE = 100\n",
        "GEN_FEATS = 32\n",
        "DIS_FEATS = 32\n",
        "NUM_CHANNELS = 1\n",
        "IMAGE_W = 28\n",
        "IMAGE_H = 28\n",
        "BATCH_SIZE = 32\n",
        "TEST_SAMPLES = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j12mfXHcYs1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8d560da0-bfd7-4bc4-a093-9446b98e2715"
      },
      "cell_type": "code",
      "source": [
        "#@title Convolutions size check (square images)\n",
        "\n",
        "in_channels = 0  #@param {type: \"slider\", min: 0, max: 100}\n",
        "out_channels = 28  #@param {type: \"slider\", min: 0, max: 100}\n",
        "image_size = 1  #@param {type: \"slider\", min: 0, max: 100}\n",
        "kernel_size = 4  #@param {type: \"slider\", min: 1, max: 10}\n",
        "stride = 1  #@param {type: \"slider\", min: 0, max: 10}\n",
        "padding = 0  #@param {type: \"slider\", min: 0, max: 10}\n",
        "\n",
        "\n",
        "transpose_out = (image_size-1) * stride - (2*padding) + kernel_size\n",
        "conv_out = (image_size + (2 * padding) - (kernel_size -1) -1) / stride + 1\n",
        "\n",
        "\n",
        "print(\"ConvTranspose shape:\", ('BS', out_channels, transpose_out, transpose_out))\n",
        "print(\"ConvTranspose shape:\", ('BS', out_channels, conv_out, conv_out))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvTranspose shape: ('BS', 28, 4, 4)\n",
            "ConvTranspose shape: ('BS', 28, -2.0, -2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jpBKOfmdjPA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mnist_data():\n",
        "    compose = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize([.5], [.5])\n",
        "        ])\n",
        "    out_dir = './dataset'\n",
        "    return datasets.FashionMNIST(root=out_dir, train=True, transform=compose, download=True)\n",
        "\n",
        "# Load data\n",
        "data = mnist_data()\n",
        "# Create loader with data, so that we can iterate over it\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# Num batches\n",
        "num_batches = len(data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dcoGRbdigkHE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_images(images):\n",
        "    images = images.numpy().reshape(images.shape[0], 28, 28)\n",
        "    \n",
        "    images_row = 6\n",
        "    num_images = len(images)\n",
        "\n",
        "    \n",
        "    f, axarr = plt.subplots((num_images // images_row) + 1, \n",
        "                            images_row)\n",
        "  \n",
        "    for ax in axarr.flatten():\n",
        "      ax.axis('off')\n",
        "  \n",
        "    for i, image in enumerate(images):\n",
        "      ax = axarr[i // images_row, i % images_row]\n",
        "      ax.imshow(image)\n",
        "    clear_output()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4y5KCwj05vGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bZoLIzPHjPBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer discriminative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        n_features = 784\n",
        "        n_out = 1\n",
        "        nc = 1\n",
        "        ndf = 64\n",
        " \n",
        "        self.conv1 = nn.Sequential(\n",
        "            # input is (nc) x 28 x 28\n",
        "            nn.Conv2d(NUM_CHANNELS, DIS_FEATS, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # state size. (ndf) x 14 x 14\n",
        "            nn.Conv2d(DIS_FEATS, DIS_FEATS*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(DIS_FEATS*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # state size. (ndf*2) x 7 x 7\n",
        "            nn.Conv2d(DIS_FEATS*2, DIS_FEATS*4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(DIS_FEATS*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.linear1 = nn.Sequential(   \n",
        "            # state size. (ndf*4) x 4 x 4\n",
        "            nn.Linear(DIS_FEATS*4 * 4 * 4, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, DIS_FEATS*4*4*4)\n",
        "        x = self.linear1(x)\n",
        "        return x\n",
        "\n",
        "discriminator = to_gpu(DiscriminatorNet())\n",
        "discriminator.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sCqRnEUjPBZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class GeneratorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer generative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "       \n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(LATENT_SIZE, GEN_FEATS*4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(GEN_FEATS*4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(GEN_FEATS*4, GEN_FEATS*2, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(GEN_FEATS*2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 7 x 7\n",
        "            nn.ConvTranspose2d(GEN_FEATS*2,GEN_FEATS, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(GEN_FEATS),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 14 x 14\n",
        "            nn.ConvTranspose2d(GEN_FEATS, NUM_CHANNELS, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (NUM_CHANNELS x 28 x 28)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.main(x)\n",
        "        return x\n",
        "\n",
        "generator = to_gpu(GeneratorNet())\n",
        "generator.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CxdqU8nGjPBh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def noise(size):\n",
        "    '''\n",
        "    Generates a 1-d vector of gaussian sampled random values\n",
        "    '''\n",
        "    n = Variable(torch.randn(size, LATENT_SIZE, 1, 1))\n",
        "    return to_gpu(n)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ry2e4hkzeLhe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gan_magic(generator, discriminator, data_loader, noise, plot_images, test_samples=TEST_SAMPLES,\n",
        "          disc_steps=1, d_lr=0.0001, g_lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
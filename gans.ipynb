{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gans.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Nto-M3lZODHK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# HELPERS\n"
      ]
    },
    {
      "metadata": {
        "id": "Tay3l2P3jPAw",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pytorch\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def to_gpu(x):\n",
        "  if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mwC8rxDpOYtt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training GANS\n"
      ]
    },
    {
      "metadata": {
        "id": "Yz-9haiC2gXo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Architecture\n",
        "\n",
        "<img src=\"https://sthalles.github.io/assets/dcgan/GANs.png\" width=\"600px\"/>\n",
        "\n",
        "## GAN seen as a *minmax* game\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1KVkTMjTT7jr8gfIv-1c4LRosrCZRpJd9)\n",
        "\n",
        "## Training procedure\n",
        "\n",
        "![alt text](https://drive.google.com/uc?export=view&id=1_JMKgK48QbhU9W9F9DG6dPQpYZPcYGSE)\n",
        "\n",
        "\n",
        "### Interesting improvements in GANs training\n",
        "* Feature matching - matching disciminators features instead of output.\n",
        "* Minibatch discrimination - appending similarity of fake images to disciminator to help him detect mode collapse\n",
        "* Label smoothing - training with smoothed labels (0.9 instead of 1.0, done only for real examples)\n",
        "* Using labels - train multi-class disciminator with *\"fake\"* as additional class\n",
        "* Play with cost funciton:\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/800/1*sE-ChIllxdrzIQBQhi33UQ.jpeg)\n",
        "[source](https://towardsdatascience.com/gan-ways-to-improve-gan-performance-acf37f9f59b)"
      ]
    },
    {
      "metadata": {
        "id": "6h8yoBSyghtR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_status(epoch, num_epochs, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "\n",
        "    # var_class = torch.autograd.variable.Variable\n",
        "    if isinstance(d_error, torch.autograd.Variable):\n",
        "        d_error = d_error.data.cpu().numpy()\n",
        "    if isinstance(g_error, torch.autograd.Variable):\n",
        "        g_error = g_error.data.cpu().numpy()\n",
        "    if isinstance(d_pred_real, torch.autograd.Variable):\n",
        "        d_pred_real = d_pred_real.data\n",
        "    if isinstance(d_pred_fake, torch.autograd.Variable):\n",
        "        d_pred_fake = d_pred_fake.data\n",
        "\n",
        "\n",
        "    print('Epoch: [{}/{}]'.format(epoch,num_epochs))\n",
        "    print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "    print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H2OPpnfrgNmP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ones_target(size):\n",
        "    '''\n",
        "    Tensor containing ones, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    return to_gpu(data)\n",
        "def zeros_target(size):\n",
        "    '''\n",
        "    Tensor containing zeros, with shape = size\n",
        "    '''\n",
        "    data = Variable(torch.zeros(size, 1))\n",
        "    return to_gpu(data)\n",
        "  \n",
        "def mones_target(size):\n",
        "    data = Variable(torch.ones(size, 1))\n",
        "    data *= -1\n",
        "    return to_gpu(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UIg3wz5dAML",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def gan_magic(generator, discriminator, data_loader, noise, plot, epochs=100,\n",
        "              disc_steps=1, test_samples=10, draw_every_n=1, d_lr=0.001, g_lr=0.001,\n",
        "              mode=\"gan\", clip=None):\n",
        "  # Total number of epochs to train\n",
        "  num_epochs = epochs\n",
        "\n",
        "  test_noise = noise(test_samples)\n",
        "  \n",
        "  if mode == \"gan\":\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=d_lr)\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=g_lr)\n",
        "  elif mode == \"wgan\":\n",
        "    # WGAN with gradient clipping uses RMSprop instead of ADAM\n",
        "    d_optimizer = torch.optim.RMSprop(discriminator.parameters(), lr=d_lr)\n",
        "    g_optimizer = torch.optim.RMSprop(generator.parameters(), lr=g_lr)\n",
        "    \n",
        "  \n",
        "  loss = nn.BCELoss()\n",
        "  \n",
        "  def train_discriminator(optimizer, real_data, fake_data):\n",
        "    N = real_data.size(0)\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1.1 Predict on Real Data\n",
        "    prediction_real = discriminator(real_data)\n",
        "    # 1.2 Predict on Fake Data\n",
        "    prediction_fake = discriminator(fake_data)\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    if mode == \"gan\":\n",
        "        error_real = loss(prediction_real, ones_target(N))\n",
        "        error_real.backward()\n",
        "        error_fake = loss(prediction_fake, zeros_target(N))\n",
        "        error_fake.backward()\n",
        "    elif mode == \"wgan\":\n",
        "        error_real = prediction_real\n",
        "        error_real.backward(ones_target(N))\n",
        "        error_fake = prediction_fake\n",
        "        error_fake.backward(mones_target(N))\n",
        "        \n",
        "    # 1.3 Update weights with gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    if mode == \"wgan\":\n",
        "        # Clip disciminator weights\n",
        "        for p in discriminator.parameters():\n",
        "            p.data.clamp_(-clip, clip)\n",
        "    \n",
        "    # Return error and predictions for real and fake inputs\n",
        "    return error_real.mean() + error_fake.mean(), prediction_real, prediction_fake\n",
        "  \n",
        "  def train_generator(optimizer, fake_data):\n",
        "    N = fake_data.size(0)\n",
        "\n",
        "    # Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Sample noise and generate fake data\n",
        "    prediction = discriminator(fake_data)\n",
        "\n",
        "    # Calculate error and backpropagate\n",
        "    if mode == \"gan\":\n",
        "      error = loss(prediction, ones_target(N))\n",
        "      error.backward()\n",
        "    elif mode == \"wgan\":\n",
        "      error = prediction\n",
        "      error.backward(ones_target(N))\n",
        "\n",
        "    # Update weights with gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # Return error\n",
        "    return error.mean()\n",
        "  \n",
        "\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "          N = real_batch.size(0)\n",
        "          \n",
        "          real_data = to_gpu(Variable(real_batch))\n",
        "\n",
        "          # 1. Train Discriminator\n",
        "          # 1.1 Generate fake data and detach \n",
        "          # (so gradients are not calculated for generator)\n",
        "          fake_data = generator(noise(N)).detach()\n",
        "          # 1.2 Train D\n",
        "          d_error, d_pred_real, d_pred_fake = \\\n",
        "              train_discriminator(d_optimizer, real_data, fake_data)\n",
        "      \n",
        "          # 2. Train Generator every \"k = disc_steps\" steps\n",
        "          if n_batch % disc_steps == 0:        \n",
        "            # 2.1 Generate fake data again\n",
        "            fake_data = generator(noise(N))\n",
        "            # 2.2 Train G\n",
        "            g_error = train_generator(g_optimizer, fake_data)\n",
        "\n",
        "      # Display samples every few batches\n",
        "      if epoch % draw_every_n == 0: \n",
        "          test_images = generator(test_noise).cpu()\n",
        "          test_images = test_images.data\n",
        "          plot(test_images)\n",
        "          \n",
        "      # Display status Logs\n",
        "      display_status(\n",
        "          epoch, num_epochs,\n",
        "          d_error, g_error, d_pred_real, d_pred_fake\n",
        "      )\n",
        "        \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qPRCr9BXOKx8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Vanilla GAN"
      ]
    },
    {
      "metadata": {
        "id": "_fuwfsnqr3LJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LATENT_SIZE = 10\n",
        "BATCH_SIZE = 32\n",
        "TEST_SAMPLES = 16\n",
        "\n",
        "def circle_noise(size):\n",
        "    '''\n",
        "    Generates a 1-d vector of gaussian sampled random values\n",
        "    '''\n",
        "    n = Variable(torch.rand(size, LATENT_SIZE))\n",
        "    return to_gpu(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tdy3147_mg_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_circles\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# generate 2d classification dataset\n",
        "X, _ = make_circles(n_samples=400, noise=0.05, factor=0.99)\n",
        "X *= 0.8\n",
        "\n",
        "def plot_circle(data):\n",
        "  xax = data[:,0]\n",
        "  yax = data[:,1]\n",
        "\n",
        "  plt.scatter(xax, yax, c='red')\n",
        "  plt.show()\n",
        "\n",
        "class CircleGenerator:\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "    \n",
        "    \n",
        "  def gen_batches(self):\n",
        "    for _ in range(len(self.data) // BATCH_SIZE):\n",
        "      dcopy = self.data.copy()\n",
        "      np.random.shuffle(dcopy)\n",
        "      yield torch.from_numpy(dcopy[:BATCH_SIZE].astype(np.float32)), None # second one just for compatibility\n",
        "\n",
        "  def __iter__(self):\n",
        "    return self.gen_batches()\n",
        "\n",
        "  \n",
        "circle_data_loader = CircleGenerator(X)\n",
        "\n",
        "plot_circle(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5hkdIMn3p7OO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DiscriminatorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer discriminative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self, is_critic=False):\n",
        "        super(DiscriminatorNet, self).__init__()\n",
        "        self.is_critic = is_critic\n",
        "        n_features = 2\n",
        "        n_out = 1\n",
        "        \n",
        "        self.hidden0 = nn.Sequential( \n",
        "            nn.Linear(n_features, 50),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(\n",
        "            nn.Linear(50, 20),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.out = nn.Sequential(\n",
        "            torch.nn.Linear(20, n_out),\n",
        "        )\n",
        "        \n",
        "        self.probas = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.out(x)\n",
        "        if not self.is_critic:\n",
        "          x = self.probas(x)\n",
        "        return x\n",
        "\n",
        "discriminator = to_gpu(DiscriminatorNet())\n",
        "\n",
        "\n",
        "class GeneratorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer generative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(GeneratorNet, self).__init__()\n",
        "        n_features = 10\n",
        "        n_out = 2\n",
        "        \n",
        "        self.hidden0 = nn.Sequential(\n",
        "            nn.Linear(n_features, 20),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        self.hidden1 = nn.Sequential(            \n",
        "            nn.Linear(20, 50),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "        \n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(50, n_out),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.hidden0(x)\n",
        "        x = self.hidden1(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "generator = to_gpu(GeneratorNet())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kE9sWonNr-47",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gan_magic(generator, discriminator, circle_data_loader, circle_noise,\n",
        "          plot_circle, epochs=1000, disc_steps=20, test_samples=200, draw_every_n=10, d_lr=0.01, g_lr=0.01)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZnfHDMzKNxmv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DCGAN"
      ]
    },
    {
      "metadata": {
        "id": "vEzlyysx8sry",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " #### DCGAN summary [(source)](https://medium.com/@jonathan_hui/gan-dcgan-deep-convolutional-generative-adversarial-networks-df855c438f)\n",
        "    \n",
        "    1. Replace all max pooling with convolutional stride\n",
        "    2. Use transposed convolution for upsampling.\n",
        "    3. Eliminate fully connected layers.\n",
        "    4. Use Batch normalization except the output layer for the generator and the input layer of the discriminator.\n",
        "    5. Use ReLU in the generator except for the output which uses tanh.\n",
        "    6. Use LeakyReLU in the discriminator."
      ]
    },
    {
      "metadata": {
        "id": "53UJlmsyu4eZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LATENT_SIZE = 100\n",
        "GEN_FEATS = 32\n",
        "DIS_FEATS = 32\n",
        "NUM_CHANNELS = 1\n",
        "IMAGE_W = 28\n",
        "IMAGE_H = 28\n",
        "BATCH_SIZE = 32\n",
        "TEST_SAMPLES = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j12mfXHcYs1t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Convolutions size check (square images)\n",
        "\n",
        "in_channels = 0  #@param {type: \"slider\", min: 0, max: 100}\n",
        "out_channels = 28  #@param {type: \"slider\", min: 0, max: 100}\n",
        "image_size = 1  #@param {type: \"slider\", min: 0, max: 100}\n",
        "kernel_size = 4  #@param {type: \"slider\", min: 1, max: 10}\n",
        "stride = 1  #@param {type: \"slider\", min: 0, max: 10}\n",
        "padding = 0  #@param {type: \"slider\", min: 0, max: 10}\n",
        "\n",
        "\n",
        "transpose_out = (image_size-1) * stride - (2*padding) + kernel_size\n",
        "conv_out = (image_size + (2 * padding) - (kernel_size -1) -1) / stride + 1\n",
        "\n",
        "\n",
        "print(\"ConvTranspose shape:\", ('BS', out_channels, transpose_out, transpose_out))\n",
        "print(\"ConvTranspose shape:\", ('BS', out_channels, conv_out, conv_out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpBKOfmdjPA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mnist_data():\n",
        "    compose = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize([.5], [.5])\n",
        "        ])\n",
        "    out_dir = './dataset'\n",
        "    return datasets.FashionMNIST(root=out_dir, train=True, transform=compose, download=True)\n",
        "\n",
        "# Load data\n",
        "data = mnist_data()\n",
        "# Create loader with data, so that we can iterate over it\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "# Num batches\n",
        "num_batches = len(data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dcoGRbdigkHE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_images(images, is_numpy=False):\n",
        "    if not is_numpy:\n",
        "      images = images.numpy()\n",
        "      \n",
        "    images = images.reshape(images.shape[0], 28, 28)\n",
        "    \n",
        "    images_row = 6\n",
        "    num_images = len(images)\n",
        "\n",
        "    \n",
        "    f, axarr = plt.subplots((num_images // images_row) + 1, \n",
        "                            images_row)\n",
        "  \n",
        "    for ax in axarr.flatten():\n",
        "      ax.axis('off')\n",
        "  \n",
        "    for i, image in enumerate(images):\n",
        "      ax = axarr[i // images_row, i % images_row]\n",
        "      ax.imshow(image)\n",
        "    clear_output()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4y5KCwj05vGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bZoLIzPHjPBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DcDiscriminatorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer discriminative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self, is_critic=False):\n",
        "        super(DcDiscriminatorNet, self).__init__()\n",
        "        self.is_critic = is_critic\n",
        "        self.conv1 = nn.Sequential(\n",
        "            # input is (nc) x 28 x 28\n",
        "            nn.Conv2d(NUM_CHANNELS, DIS_FEATS, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            # state size. (ndf) x 14 x 14\n",
        "            nn.Conv2d(DIS_FEATS, DIS_FEATS*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(DIS_FEATS*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            # state size. (ndf*2) x 7 x 7\n",
        "            nn.Conv2d(DIS_FEATS*2, DIS_FEATS*4, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(DIS_FEATS*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.linear1 = nn.Sequential(   \n",
        "            # state size. (ndf*4) x 4 x 4\n",
        "            nn.Linear(DIS_FEATS*4 * 4 * 4, 1),\n",
        "        )\n",
        "        \n",
        "        self.probas = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, DIS_FEATS*4*4*4)\n",
        "        x = self.linear1(x)\n",
        "        if not self.is_critic:\n",
        "          x = self.probas(x)\n",
        "        return x\n",
        "\n",
        "discriminator = to_gpu(DcDiscriminatorNet())\n",
        "discriminator.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9sCqRnEUjPBZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class DcGeneratorNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    A three hidden-layer generative neural network\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(DcGeneratorNet, self).__init__()\n",
        "       \n",
        "        self.convt1 = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d(LATENT_SIZE, GEN_FEATS*4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(GEN_FEATS*4),\n",
        "            nn.ReLU(True))\n",
        "        \n",
        "        self.convt2 = nn.Sequential(\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(GEN_FEATS*4, GEN_FEATS*2, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(GEN_FEATS*2),\n",
        "            nn.ReLU(True))\n",
        "        \n",
        "        self.convt3 = nn.Sequential(\n",
        "            # state size. (ngf*4) x 7 x 7\n",
        "            nn.ConvTranspose2d(GEN_FEATS*2,GEN_FEATS, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(GEN_FEATS),\n",
        "            nn.ReLU(True))\n",
        "        \n",
        "        self.convt4 = nn.Sequential(\n",
        "            # state size. (ngf*2) x 14 x 14\n",
        "            nn.ConvTranspose2d(GEN_FEATS, NUM_CHANNELS, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (NUM_CHANNELS x 28 x 28)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convt1(x)\n",
        "        x = self.convt2(x)\n",
        "        x = self.convt3(x)\n",
        "        x = self.convt4(x)\n",
        "        return x\n",
        "\n",
        "generator = to_gpu(DcGeneratorNet())\n",
        "generator.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CxdqU8nGjPBh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fmnist_noise(size):\n",
        "    '''\n",
        "    Generates a 1-d vector of gaussian sampled random values\n",
        "    '''\n",
        "    n = Variable(torch.randn(size, LATENT_SIZE, 1, 1))\n",
        "    return to_gpu(n)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ry2e4hkzeLhe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gan_magic(generator, discriminator, data_loader, fmnist_noise, plot_images, test_samples=TEST_SAMPLES,\n",
        "          disc_steps=1, d_lr=0.0001, g_lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7SyDdDm19pUM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Interpolate"
      ]
    },
    {
      "metadata": {
        "id": "hrql_klEC58B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "noise = fmnist_noise(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ubUZQBRp9o_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images = generator(noise).cpu().data\n",
        "plot_images(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_iwRFYK5BlQH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "noise1 = noise[0]\n",
        "noise2 = noise[2]\n",
        "\n",
        "interpolation = []\n",
        "\n",
        "for ratio in np.linspace(0,1,10):\n",
        "  value = noise1 * (1-ratio) + noise2 * ratio\n",
        "  img = generator(value[None,:,:,:]).cpu().data.numpy()\n",
        "  interpolation.append(img.squeeze())\n",
        "  \n",
        "interpolation = np.array(interpolation)\n",
        "  \n",
        "plot_images(interpolation, is_numpy=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zjJdeHLruRye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# WGAN"
      ]
    },
    {
      "metadata": {
        "id": "F9_4IHxTuUjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Wasserstein distance\n",
        "\n",
        "![](https://cdn-images-1.medium.com/max/800/1*6y-tz57odJpHh4pwRfXACw.png)\n",
        "\n",
        "## Discriminator → Critic\n",
        "\n",
        "<img src=\"https://i.imgflip.com/2x6470.jpg\" alt=\"Drawing\" height=\"400px;\"/>\n",
        "\n",
        "## Cost functions\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/2600/1*5jF5gbIDwU6k9m1ILl0Utg.jpeg\" width=\"800px\"/>\n",
        "[source](https://medium.com/@jonathan_hui/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490)\n",
        "\n",
        "## Training procedure\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/1*JOg9lC2JLl2Crmx5uk6S2g.png\" width=\"800px\"/>\n",
        "[source](https://medium.com/@jonathan_hui/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490)"
      ]
    },
    {
      "metadata": {
        "id": "piyFeZtl7MlN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### WGAN"
      ]
    },
    {
      "metadata": {
        "id": "6DiTSwrzvO9z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del discriminator\n",
        "del generator\n",
        "\n",
        "LATENT_SIZE = 10\n",
        "BATCH_SIZE = 32\n",
        "TEST_SAMPLES = 16\n",
        "\n",
        "circle_data_loader = CircleGenerator(X)\n",
        "\n",
        "plot_circle(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qqy0yLwpy1Ra",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = to_gpu(GeneratorNet())\n",
        "discriminator = to_gpu(DiscriminatorNet(is_critic=True))\n",
        "\n",
        "gan_magic(generator, discriminator, circle_data_loader, circle_noise,\n",
        "          plot_circle, epochs=1000, disc_steps=20, test_samples=200, draw_every_n=10, d_lr=0.01, g_lr=0.01,\n",
        "          mode=\"wgan\", clip=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_EGglgz_7RvS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DCWGAN"
      ]
    },
    {
      "metadata": {
        "id": "-GBhQjSK7cZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del generator\n",
        "del discriminator\n",
        "\n",
        "generator = to_gpu(DcGeneratorNet())\n",
        "generator.apply(weights_init)\n",
        "\n",
        "discriminator = to_gpu(DcDiscriminatorNet())\n",
        "discriminator.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WrxZZQDg7V4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gan_magic(generator, discriminator, data_loader, fmnist_noise, plot_images, test_samples=TEST_SAMPLES,\n",
        "          disc_steps=1, d_lr=0.0001, g_lr=0.0001, mode=\"wgan\", clip=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}